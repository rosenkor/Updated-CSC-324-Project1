---
title: "Kory"
author: "Kory Rosen"
date: "2024-03-10"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(RPostgres)
library(stringr)
library(jsonlite)

creds <- read_json("credentials.json")

con <- dbConnect(Postgres(),
                 host = creds$host,
                 port = creds$port,
                 dbname = creds$dbname,
                 user = creds$user,
                 password = creds$password)

query <- "SELECT * FROM public.feather2"
data <- dbGetQuery(con, query)

# Work with the data

dbDisconnect(con)
```



 
```{r}

library(shiny)
library(ggplot2)
library(dplyr)
library(broom)
library(stringr)
library(tm)
library(wordcloud2)
library(plotly)
library(syuzhet)
library(DT)
library(shinyWidgets)
library(topicmodels)

data$opinions_text <- lapply(data$opinions_text, unlist)

# Preprocess the data
data$opinions_text <- str_remove_all(data$opinions_text, "\\[|\\]|'")
```

```{r}
library(shiny)
library(ggplot2)
library(dplyr)
library(broom)
library(stringr)
library(tm)
library(future)
library(wordcloud2)
library(plotly)
library(syuzhet)
library(DT)
library(shinyWidgets)
library(topicmodels)
library(NLP)

data$opinions_text <- lapply(data$opinions_text, unlist)

# Preprocess the data
data$opinions_text <- str_remove_all(data$opinions_text, "\\[|\\]|'")

data2 <- data
data2$sub_opinions <- as.character(data2$sub_opinions)

clean_and_split_text <- function(text_vector) {
  all_sections <- list()
  
  for (text_element in 1:length(text_vector)) {
    text_element <- text_vector[text_element]
    # Replace the specific pattern \",\" with a unique delimiter, e.g., "|||"
    temp_text <- gsub("\\\",\\\"", "|||", text)

    # Split the text using the unique delimiter
    split_result <- strsplit(temp_text, "\\|\\|\\|")
    
    if (length(split_result) > 0) {
      hi <- split_result[[1]]
      hi <- lapply(hi, function(x) gsub("^\\{\"", "", x))
      hi <- lapply(hi, function(x) gsub("\\\"\\}$", "", x))
      
      split_word <- "SUPREME COURT OF THE UNITED STATES"
      delimiter <- "@@@SPLIT_HERE@@@"
      
      text_with_delimiter <- lapply(hi, function(text) {
        str_replace_all(text, fixed(split_word), paste0(delimiter, split_word))
      })
      
      sections <- lapply(text_with_delimiter, function(text) {
        unlist(strsplit(text, delimiter))
      })
      
      sections <- lapply(sections, function(section) {
        unique(section[section != ""])
      })
      
      all_sections <- c(all_sections, unlist(sections))
    }
  }

  return(unique(all_sections))
}

extract_author_name <- function(text) {
  pattern <- "JUSTICE\\s(\\w+)"
  last_names <- str_extract_all(text, pattern)[[1]]
  
  if (length(last_names) > 0) {
    last_names <- str_replace_all(last_names, "JUSTICE\\s", "")
    # Convert the last names to title case to match the format in author_info
    last_names <- tools::toTitleCase(last_names)
    # Return the first last name from the list
    return(last_names[1])
  }
  
  return(NA)
}

extract_author <- function(opinion_text, author_info) {
  author_last_name <- extract_author_name(opinion_text)
  
  opinion_attributes <- list(
    author_id = NA,
    full_name = NA,
    date_dob = NA,
    date_left = NA,
    date_start = NA,
    political_party = NA
  )
  
  if (!is.na(author_last_name)) {
    # Find the corresponding row in author_info based on the last name
    author_row <- author_info[author_info$last_name == author_last_name, ]
    
    if (nrow(author_row) > 0) {
      opinion_attributes$author_id <- author_row$author_id[1]
      opinion_attributes$full_name <- author_row$full_name[1]
      opinion_attributes$date_dob <- author_row$date_dob[1]
      opinion_attributes$date_left <- author_row$date_left[1]
      opinion_attributes$date_start <- author_row$date_start[1]
      opinion_attributes$political_party <- author_row$political_party[1]
    }
  }
  
  return(opinion_attributes)
}

new_rows <- list()

data2$original <- TRUE
data2$text_type <- "Default"

author_info <- data2 %>%
  group_by(full_name) %>%
  summarize(
    author_id = first(author_id),
    date_dob = first(date_dob),
    date_left = first(date_left),
    date_start = first(date_start),
    political_party = first(political_party)
  ) %>%
  ungroup()

# Define a function to extract the last name
extract_last_name <- function(full_name) {
  name_parts <- strsplit(full_name, " ")[[1]]
  last_name <- name_parts[length(name_parts)]
  
  # Handle suffixes like "jr" by using the second-to-last word as the last name
  if (tolower(last_name) %in% c("jr", "sr", "ii", "iii")) {
    last_name <- name_parts[length(name_parts) - 1]
  }
  
  return(toupper(last_name))
}

# Apply the function to the full names in author_info
author_info$last_name <- sapply(author_info$full_name, extract_last_name)

# Create a lookup table
lookup_table <- author_info %>% select(last_name, full_name)

opinion_of_the_court_regex <- "^(OPINION\\s+OF\\s+THE\\s+COURT|OPINION\\s+DELIVERED\\s+BY)"
concurring_regex <- "^JUSTICE\\s+\\w+,\\s+(with\\s+whom\\s+)?(JUSTICE\\s+\\w+(\\s+and\\s+JUSTICE\\s+\\w+)?|THE\\s+CHIEF\\s+JUSTICE)(,\\s+)?concurring"
dissenting_regex <- "^JUSTICE\\s+\\w+,\\s+(with\\s+whom\\s+)?(JUSTICE\\s+\\w+(\\s+and\\s+JUSTICE\\s+\\w+)?|THE\\s+CHIEF\\s+JUSTICE)(,\\s+)?dissenting"


# Iterate over each row in the dataframe
for (i in 1:nrow(data2)) {
  # Apply the cleaning and splitting function to the opinions_text column
  text <- data2$opinions_text[i]
  sections <- clean_and_split_text(text)
  
for (section in sections) {
  new_row <- data2[i, ]
  new_row$original <- FALSE
  new_row$opinions_text <- section
  
  if (is.na(section)) next
  
  # Find the position of the first match for each pattern
  positions <- c(
    syllabus_pos = regexpr("SUPREME COURT OF THE UNITED STATES Syllabus", section),
    opinion_pos = regexpr("opinion of the Court", section, ignore.case = TRUE),
    concurring_pos = regexpr("concurring", section, ignore.case = TRUE),
    dissenting_pos = regexpr("dissenting", section, ignore.case = TRUE)
  )
  
  # Filter out positions with no match
  matched_positions <- positions[positions > 0]
  
  # Set text_type based on the earliest position
  if (length(matched_positions) > 0) {
    min_pos <- names(matched_positions)[which.min(matched_positions)]
    switch(min_pos,
           syllabus_pos = {
             new_row$text_type <- "Syllabus"
             new_row$full_name <- NA
             new_row$date_start <- NA
             new_row$date_dob <- NA
             new_row$political_party <- NA
             new_row$date_left <- NA
             new_row$author_id <- NA
           },
           opinion_pos = {
             new_row$text_type <- "Opinion of the Court"
           },
           concurring_pos = {
             new_row$text_type <- "Concurring Opinion"
             opinion_attributes <- extract_author(section, author_info)
             new_row$author_id <- opinion_attributes$author_id
             new_row$full_name <- opinion_attributes$full_name
             new_row$date_dob <- opinion_attributes$date_dob
             new_row$date_left <- opinion_attributes$date_left
             new_row$date_start <- opinion_attributes$date_start
             new_row$political_party <- opinion_attributes$political_party
           },
           dissenting_pos = {
             new_row$text_type <- "Dissenting Opinion"
             opinion_attributes <- extract_author(section, author_info)
             new_row$author_id <- opinion_attributes$author_id
             new_row$full_name <- opinion_attributes$full_name
             new_row$date_dob <- opinion_attributes$date_dob
             new_row$date_left <- opinion_attributes$date_left
             new_row$date_start <- opinion_attributes$date_start
             new_row$political_party <- opinion_attributes$political_party
           }
    )
  } else {
    new_row$text_type <- "Other"
    new_row$full_name <- NA
    new_row$date_start <- NA
    new_row$date_dob <- NA
    new_row$political_party <- NA
    new_row$date_left <- NA
    new_row$author_id <- NA
  }
  
  new_rows <- c(new_rows, list(new_row))
}
}

# Combine the new rows with the original dataframe
data2 <- bind_rows(data2, do.call(rbind, new_rows))

data2 <- data2[data2$original == FALSE, ]

data2 <- unique(data2)
rownames(data2) <- NULL

data2$opinions_text <- gsub("SUPREME COURT OF THE UNITED STATES", "", data2$opinions_text)
data2$opinions_text <- gsub("_+ Nos? \\d+( \\d+)?( \\d+)?( and \\d+)? _+ ", "", data2$opinions_text)
data2$opinions_text  <- ifelse(data2$text_type != "Other" & data2$text_type != "Syllabus",
                  sub(".*?(JUSTICE)", "\\1", data2$opinions_text ),
                  data2$opinions_text)
data2$opinions_text  <- ifelse(data2$text_type == "Opinion of the Court",
                  sub(".*?delivered the opinion of the Court", "", data2$opinions_text ),
                  data2$opinions_text)

data2 <- data2 %>%
  group_by(case_name) %>%
  filter("Opinion of the Court" %in% text_type) %>%
  ungroup()

data2$opinions_text  <- ifelse(data2$text_type == "Syllabus",
                  sub(".*Decided\\s*\\w+\\s+\\d{1,2},?\\s+\\d{4}\\s*(.*)", "\\1", data2$opinions_text ),
                  data2$opinions_text)

data2$opinions_text  <- ifelse(data2$text_type == "Dissenting Opinion",
                  sub(".*?dissenting", "", data2$opinions_text ),
                  data2$opinions_text)

data2$opinions_text <- gsub("\\p{Pd}+", "-", data2$opinions_text, perl = TRUE)

data2$date_filed <- as.Date(data2$date_filed)
data2$date_dob <- as.Date(data2$date_dob)
data2$date_start <- as.Date(data2$date_start)
data2$date_left <- as.Date(data2$date_left)

# Adjust the regex to include en dash and em dash
#data2$opinions_text <- gsub("([a-zA-Z]+)*-*([a-zA-Z]+)", "\\1\\2", data2$opinions_text)
```

```{r}
library(reticulate)
pd <- import("pandas")
re <- import("re")

df <- data2  # Assuming 'data2' is your DataFrame in R

# Convert dates from POSIXct/POSIXlt to character to avoid conversion issues
df$date_filed <- as.character(df$date_filed)
df$date_dob <- as.character(df$date_dob)
df$date_start <- as.character(df$date_start)
df$date_left <- as.character(df$date_left)

# Convert R dataframe to pandas dataframe
py$pandas_df <- r_to_py(df)

exec_py2 <- '
import pandas as pd
import numpy as np
import re

# Access the DataFrame stored in the global environment
pandas_df = globals()["pandas_df"]

pandas_df["date_filed"] = pd.to_datetime(pandas_df["date_filed"])
pandas_df["date_dob"] = pd.to_datetime(pandas_df["date_dob"])
pandas_df["date_start"] = pd.to_datetime(pandas_df["date_start"])
pandas_df["date_left"] = pd.to_datetime(pandas_df["date_left"])

HEADER_REGEX = "Cite as:? \\\\d+ U\\\\.?S\\\\.? \\\\_\\\\_\\\\_\\\\_? \\\\(\\\\d+\\\\)"
FOOTER_REGEX = "(?:\\\\d+ )?(?:Ibid|\\\\[A-Z \\\\]+ v\\\\. \\\\[A-Z \\\\]+)(?: \\\\[A-Z\\\\]+ (?:C\\\\. )?J\\\\.,? (?:concurring|dissenting|concurring in (?:the )?judgment))?(?! of)"
SYLLABUS_REGEX = "Syllabus,?\\\\.\\\\*\\\\?(?=(?:Opinion|Concurring Opinion|Dissenting Opinion) (?:of the Court|of the court))"
JUSTICE_REGEX = "(?:\\\\[A-Z\\\\]+, )+(?:C\\\\. )?J\\\\.,? (?:concurring|dissenting|concurring in (?:the )?judgment|delivered the opinion (?:of the Court|for a unanimous Court))"
NOTICE_REGEX = "NOTICE:? This opinion is subject to formal revision before publication in the (?:preliminary print|United States Reports) \\\\[^.\\\\]\\\\*\\\\."
REPORTER_REGEX = "Readers are requested to notify the Reporter of Decisions \\\\[^.\\\\]\\\\*\\\\."
BLANK_LINE_REGEX = "\\\\n\\\\s\\\\*\\\\n"
WHITESPACE_REGEX = "\\\\s+"
PAGE_NUMBER_REGEX = "\\d+ (?:Cite as|\\b[A-Z]+ v\\. [A-Z]+)"
FOOTNOTE_REGEX = " ?\\\\[\\\\d+\\\\]"


# Function to clean text in each row
def clean_text(text):
    text = re.sub(HEADER_REGEX, "", text)
    text = re.sub(FOOTER_REGEX, "", text)
    text = re.sub(SYLLABUS_REGEX, "", text, flags=re.DOTALL)
    text = re.sub(JUSTICE_REGEX, "", text)
    text = re.sub(NOTICE_REGEX, "", text)
    text = re.sub(REPORTER_REGEX, "", text)
    text = re.sub(BLANK_LINE_REGEX, "\\n", text)
    text = re.sub(WHITESPACE_REGEX, " ", text)
    text = re.sub(PAGE_NUMBER_REGEX, "", text)
    text = re.sub(FOOTNOTE_REGEX, "", text)
    return text


# Apply cleaning function
pandas_df["opinions_text"] = pandas_df["opinions_text"].apply(clean_text)


def merge_hyphenated_words(text):
    # Define the regular expression pattern
    pattern = r"[a-zA-Z]+\\s*-\\s+[a-zA-Z]+|[a-zA-Z]+\\s+-\\s*[a-zA-Z]+"

    # Function to replace each match
    def replace(match):
        # Remove all whitespace and dashes from the match
        return re.sub(r"\\s*-\\s*", "", match.group())

    # Use re.sub with the replace function to modify the text
    return re.sub(pattern, replace, text)


pandas_df["opinions_text"] = pandas_df["opinions_text"].apply(merge_hyphenated_words)

def skip_until_sentence_case(text):
    # Check if the first word is "JUSTICE"
    if text.startswith("JUSTICE"):
        # Pattern to find the first sentence case word and capture everything after it
        pattern = r"\\b[A-Z]([a-z])*\\b"
        # Search for the pattern and get the position
        match = re.search(pattern, text)
        if match:
            return text[match.start():]  # Return everything from the first sentence case word onward
    return text  # Return the original text if "JUSTICE" is not the first word
    
pandas_df["opinions_text"] = pandas_df["opinions_text"].apply(skip_until_sentence_case)

# Convert dates back to string format for R compatibility
pandas_df["date_filed"] = pandas_df["date_filed"].dt.strftime("%Y-%m-%d")
pandas_df["date_dob"] = pandas_df["date_dob"].dt.strftime("%Y-%m-%d")
pandas_df["date_start"] = pandas_df["date_start"].dt.strftime("%Y-%m-%d")
pandas_df["date_left"] = pandas_df["date_left"].dt.strftime("%Y-%m-%d")

# Ensure the DataFrame is updated in the global environment
globals()["pandas_df"] = pandas_df
'

py_run_string(exec_py2)

df_clean <- py$pandas_df

# Convert dates from character to Date class
df_clean$date_filed <- as.Date(df_clean$date_filed)
df_clean$date_dob <- as.Date(df_clean$date_dob)
df_clean$date_start <- as.Date(df_clean$date_start)
df_clean$date_left <- as.Date(df_clean$date_left)
```

```{r}

# Calculate the word count
df_clean$word_count <- sapply(strsplit(df_clean$opinions_text, " "), length)

# Remove metadata texts and Slip Opinion text
df_clean <- df_clean[df_clean$word_count > 74, ]
df_clean <- df_clean[!df_clean$word_count %in% c(125, 126, 127, 128, 129), ]


```

```{r}
library(tidyverse)
library(shinycssloaders)
library(shinyjs)
library(data.table)
library(quanteda)
library(shinythemes)
library(future)

df_clean <- df_clean %>%
  select(-cluster_id, -sub_opinions, -opinion_id, -docket_id, -original)

df_clean <- df_clean %>%
  select(case_name, date_filed, decision, scdb_votes_majority, scdb_votes_minority, opinions_cited, text_type, opinions_text, word_count, full_name, author_id, political_party, date_dob, date_start, date_left )
rownames(df_clean) <- NULL
```

```{r}
library(Dict)
df_clean$opinions_cited <- as.numeric(df_clean$opinions_cited)
remove_almost_duplicates_within_groups <- function(datav, group_columns, text_column, threshold) {
  # Group the data by the specified group columns
  data_grouped <- datav %>%
    group_by(across(all_of(group_columns))) %>%
    group_split()

  # Function to remove almost duplicates within a single group
  remove_duplicates <- function(group_data) {
    if (nrow(group_data) <= 1) {
      return(group_data)
    }

    keep_indices <- c(1)  # Keep the first text by default

    for (i in 2:nrow(group_data)) {
      is_duplicate <- FALSE

      for (j in keep_indices) {
        similarity <- 1 - stringdist::stringdist(group_data[[text_column]][i], group_data[[text_column]][j], method = "jaccard")
        if (similarity >= threshold) {
          is_duplicate <- TRUE
          break
        }
      }

      if (!is_duplicate) {
        keep_indices <- c(keep_indices, i)
      }
    }

    return(group_data[keep_indices, ])
  }

  # Apply the remove_duplicates function to each group
  data_cleaned <- lapply(data_grouped, remove_duplicates)

  # Combine the cleaned groups back into a single dataframe
  data_cleaned <- bind_rows(data_cleaned)

  return(data_cleaned)
}

# Set the similarity threshold (e.g., 0.8 for 80% similarity)
similarity_threshold <- 0.9

# Remove almost duplicates from the opinions_text column within each case_name and text_type group
df_clean <- remove_almost_duplicates_within_groups(df_clean, c("case_name", "text_type"), "opinions_text", similarity_threshold)
```

```{r}
ui <- fluidPage(
  theme = shinytheme("cerulean"),
  useShinyjs(),
  titlePanel("Supreme Court Opinions Analysis"),
  
  sidebarLayout(
    sidebarPanel(
          dateRangeInput("year_range", "Select Year Range:",
                   start = min(df_clean$date_filed), end = max(df_clean$date_filed),
                   format = "yyyy-mm-dd"),
    selectizeInput("case_name", "Select Case Name:",
                   choices = unique(df_clean$case_name),
                   multiple = TRUE,
                   options = list(placeholder = "Select case(s)")),
    conditionalPanel(
      condition = "input.tabs != 'Vote Splits Distribution'",
      selectInput("author", "Select Author:", 
                  choices = c("All", unique(df_clean$full_name))),
      pickerInput("decision_type", "Select Decision Type:",
                  choices = unique(df_clean$decision),
                  multiple = TRUE,
                  options = list(`actions-box` = TRUE)),
      pickerInput("text_type", "Select Text Type:",
                  choices = unique(df_clean$text_type),
                  multiple = TRUE,
                  options = list(`actions-box` = TRUE)),
      pickerInput("political_party", "Select Political Leaning of Opinion writer:",
                  choices = unique(df_clean$political_party),
                  multiple = TRUE,
                  options = list(`actions-box` = TRUE))
    )
    ),
    
    mainPanel(
      tabsetPanel(
        id = "tabs",
        tabPanel("Opinion Length",
                 plotlyOutput("opinion_length_plot")%>% withSpinner(),
                 textOutput("opinion_length_avg")),
        tabPanel("Vote Splits Distribution",
                 plotlyOutput("vote_outcomes_plot") %>% withSpinner()),
        tabPanel("Word Cloud",
                 wordcloud2Output("interactive_word_cloud")%>% withSpinner()),
        tabPanel("Sentiment Analysis",
                 plotOutput("sentiment_plot")%>% withSpinner())
      )
    )
  )
)

server <- function(input, output) {
  options(shiny.http.response.timeout = 300)
  
  observe({
    selected_text_type <- input$text_type
    
    if ("Syllabus" %in% selected_text_type || "Other" %in% selected_text_type) {
      shinyjs::hide("author")
      shinyjs::hide("political_party")
    } else {
      shinyjs::show("author")
      shinyjs::show("political_party")
    }
  })
  
  filtered_data2 <- reactive({
        data2_filtered <- df_clean
    
    if (input$author != "All" && !("Syllabus" %in% input$text_type)) {
      data2_filtered <- data2_filtered %>% filter(full_name == input$author)
    }
    
    data2_filtered <- data2_filtered %>%
      filter(date_filed >= input$year_range[1] & date_filed <= input$year_range[2])
    
    if (!is.null(input$decision_type) && length(input$decision_type) > 0) {
      data2_filtered <- data2_filtered %>% filter(decision %in% input$decision_type)
    }
    
    if (!is.null(input$text_type) && length(input$text_type) > 0) {
      data2_filtered <- data2_filtered %>% filter(text_type %in% input$text_type)
    }
    
    if (!is.null(input$political_party) && length(input$political_party) > 0 && !("Syllabus" %in% input$text_type)) {
      data2_filtered <- data2_filtered %>% filter(political_party %in% input$political_party)
    }
    
    if (!is.null(input$case_name) && length(input$case_name) > 0) {
      data2_filtered <- data2_filtered %>% filter(case_name %in% input$case_name)
    }
    
    data2_filtered
  })
  
  
  output$opinion_length_plot <- renderPlotly({
    plot_ly(filtered_data2(), x = ~date_filed, y = ~word_count, type = "scatter", mode = "markers",
            marker = list(size = 10, color = ~word_count, colorscale = "Viridis",
                          showscale = TRUE),
            text = ~paste("Case:", case_name, "<br> Type of Text: ", text_type, "<br> Written by:", full_name),
            hoverinfo = "text") %>%
      layout(title = "Opinion Length Over Time",
             xaxis = list(title = "Date Filed"),
             yaxis = list(title = "Opinion Length (Words)"))
  })
  
  output$opinion_length_avg <- renderText({
    avg_length <- round(mean(filtered_data2()$word_count))
    paste("Average Opinion Length:", avg_length, "words")
  })
  
output$vote_outcomes_plot <- renderPlotly({
    vote_data <- filtered_data2() %>%
      filter(!is.na(scdb_votes_majority) & !is.na(scdb_votes_minority)) %>%
      mutate(vote_split = paste(scdb_votes_majority, "-", scdb_votes_minority, sep = "")) %>%
      count(vote_split) %>%
      arrange(desc(n))
    
   
    unique_splits <- unique(vote_data$vote_split)
    colors <- setNames(RColorBrewer::brewer.pal(n = length(unique_splits), name = "Set1"), unique_splits)
    
    plot_ly(vote_data, x = ~vote_split, y = ~n, type = "bar",
            marker = list(color = ~colors[vote_split], line = list(color = ~colors[vote_split], width = 2))) %>%
      layout(title = "Vote Split By Cases", xaxis = list(title = "Vote Split"), yaxis = list(title = "Number of Cases"))
 })

# Create a plan for parallel execution
plan(multisession)

word_freqs <- reactive({
  req(filtered_data2())
  text <- filtered_data2()$opinions_text
  
  if (length(text) == 0) {
    return(NULL)
  }
  
  # Create a corpus from the text data
  corpus <- corpus(text)
  
  # Preprocess the text data in parallel
  corpus <- corpus %>%
    tokens(remove_punct = TRUE, remove_numbers = TRUE, remove_symbols = TRUE) %>%
    tokens_tolower() %>%
    tokens_remove(stopwords("en"))
  
  # Create a document-feature matrix
  dfm <- dfm(corpus)
  
  # Convert to data.table and compute word frequencies
  dt <- data.table(as.matrix(dfm))
  word_freqs <- dt[, lapply(.SD, sum)]
  
  # Convert to data.frame and sort by frequency
  word_freqs <- data.frame(word = colnames(word_freqs), freq = as.numeric(word_freqs))
  word_freqs <- word_freqs[order(-word_freqs$freq), ]
  
  return(word_freqs)
})

preprocessed_text <- reactive({
  req(word_freqs())
  top_words <- head(word_freqs(), 100)
  return(top_words)
})

output$interactive_word_cloud <- renderWordcloud2({
  req(preprocessed_text())
  wordcloud2(preprocessed_text(), size = 0.7, color = "random-dark", rotateRatio = 0.5, shape = "circle")
})
  
  output$sentiment_plot <- renderPlot({
    text <- filtered_data2()$opinions_text
    sentiment_scores <- get_nrc_sentiment(text)
    sentiment_sums <- colSums(sentiment_scores)
    
    barplot(sentiment_sums, main = "Sentiment Analysis",
            xlab = "Sentiment", ylab = "Count",
            col = rainbow(length(sentiment_sums)))
  })
  
}

shinyApp(ui, server)
```